{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-time Home Buyers Dataset Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and [original dataset] (https://drive.google.com/file/d/1sCY9CA7IO7rSXrp9OYW2AKHJxusD68jD/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.gridspec as gridspec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('mortgages.csv')\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "source": [
    "### 1 - Estimate which subset of the dataset is first-time home buyers in New York and New England, and whether that subset is large enough for analysis\n",
    "\n",
    "In order to determine the subset of first-time home buyers, the dataset is filtered based on the following criteria:\n",
    "* **Loan Purpose**: Because first-time home buyers have not owned a property before, it is reasonable to conclude that their purpose for getting a loan mortgage is to purchase a new home, not to refinance. Thus, I filter the dataset to keep only value ‘1’, which is Home purchase, in *loan_purpose* column.\n",
    "* **Business or Commercial Purpose**: The main purpose of this report is to focus on first-time home buyers, so I exclude the mortgage applications for business or commercial purpose. Specifically, I remove all entries that have value ‘1’ in *business_or_commercial_purpose* column.\n",
    "* **Occupancy Type**: Only home buyers looking to purchase a primary residence are included because second residence and investment property purchase tend to have stricter and more complicated requirements which first-time home buyers typically can’t qualify. Therefore, only entries with value ‘1’ in *occupancy_type* column remain in our subset.\n",
    "* **Applicant and Co-applicant Age**: First-time home buyers’ median age has been in the 31 to 34 range in the past years, which gives me a motive to exclude applicants and co-applicants whose age is above 62. In other words, entries with value ‘Yes’ in *applicant_age_above_62* and *co_applicant_age_above_62* columns are eliminated.\n",
    "* **Reverse Mortgage**: As explained above, applicants who are above 62 years old are unlikely to purchase a home for the first time. Reverse mortgage is designed solely for seniors who are 62 years old or older, in which lenders pay the homeowners. Consequently, applications that are reported as reverse mortgage are excluded and entries with value ‘1’ in *reverse_mortgage* column are removed.\n",
    "\n",
    "Additionally, while examining the summary statistics of *income* and *loan_amount* columns, there are multiple negative values in *income* column and a few extremely high outliers in both columns, which could be due to data errors. Therefore, I only keep entries that have income and loan amount between 0 and 15 million dollars. I also divided *loan_amount* and *property_value* columns by 1,000 so that the values will be in thousands of dollars to make it consistent with income column values for more accurate comparisons.\n",
    "\n",
    "After applying the above filters and removing 3 redundant columns, the final data subset contains 349,093 rows and 99 columns, which is approximately 33% of the original data. This filtered portion reasonably represents the first-time home buyers segment and is large enough to proceed with more detailed analyses.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN ORIGINAL DATA\n",
    "\n",
    "# drop redundant columns\n",
    "df.drop(['Unnamed: 0', 'Unnamed: 0.1', 'activity_year'], inplace=True, axis=1)\n",
    "\n",
    "# add column for 'approved' or 'denied' status\n",
    "def loan_status (row):\n",
    "    if (row.action_taken == 1) | (row.action_taken == 6) | (row.action_taken == 2) | (row.action_taken == 8):\n",
    "        return 'Approved'\n",
    "    if (row.action_taken == 3) | (row.action_taken == 7):\n",
    "        return 'Denied'\n",
    "df['loan_status']=df.apply(loan_status,axis=1) \n",
    "\n",
    "# make loan_amount in thousands of dollars unit to be consistent with income unit\n",
    "df['loan_amount'] = df['loan_amount']/1000\n",
    "\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT DATA SUBSET\n",
    "\n",
    "subset = df[(df.loan_purpose == 1) #keep \"Home Purchase\" for loan purpose\n",
    "        & (df.business_or_commercial_purpose != 1) #remove business/commercial purpose\n",
    "        & (df.occupancy_type == 1) #keep only \"principal residence\" \n",
    "        & (df.applicant_age_above_62 != 'Yes') \n",
    "        & (df.co_applicant_age_above_62 != 'Yes')\n",
    "        & (df.reverse_mortgage != 1) #remove those qualifies for reverse mortgage\n",
    "        ]\n",
    "\n",
    "# exclude outliers in income and loan_amount columns\n",
    "subset=subset[(subset.income.between(0, 15000)) & (subset.loan_amount <= 15000)]\n",
    "\n",
    "print(subset.shape)\n",
    "# print(subset.info())"
   ]
  },
  {
   "source": [
    "### 2 - Exploratory Data Analysis\n",
    "\n",
    "#### Demographics of first-time home buyers\n",
    "\n",
    "First of all, I analyze the demographics of first-time home buyers in order to provide a general idea of who these buyers are. \n",
    "\n",
    "* There are approximately 230,000 mortgage applications from buyers in 25-34 and 35-44 age groups in 2018, which account for two-third of the first-time buyers subset. \n",
    "* There are more male applicants than female applicants; however, joint applicants actually make up for the biggest fraction as couples are more likely to buy a home for their new families. \n",
    "* Nearly 70% of the first-time home buyers subset is White, followed by only 8% of Asian and 5% of Black or African American. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid', font_scale=1.3) #set overall graph style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age\n",
    "age=pd.DataFrame(subset.applicant_age.value_counts())\n",
    "age=age.reindex(['<25','25-34','35-44','45-54','55-64','8888'])\n",
    "age.columns=['Applications']\n",
    "age['Median income']=subset.groupby('applicant_age')['income'].median()\n",
    "age['Median loan_amount']=subset.groupby('applicant_age')['loan_amount'].median()\n",
    "age['Median interest rate']=subset.groupby('applicant_age')['interest_rate'].median()\n",
    "age=age.rename(index={'8888': 'No info'})\n",
    "\n",
    "# gender\n",
    "gender=pd.DataFrame(subset.derived_sex.value_counts())\n",
    "gender.columns=['Applications']\n",
    "gender['Median income']=subset.groupby('derived_sex')['income'].median()\n",
    "gender['Median loan_amount']=subset.groupby('derived_sex')['loan_amount'].median()\n",
    "gender['Median interest rate']=subset.groupby('derived_sex')['interest_rate'].median()\n",
    "\n",
    "# race\n",
    "race=pd.DataFrame(subset.derived_race.value_counts())\n",
    "race.columns=['Applications']\n",
    "race['Median income']=subset.groupby('derived_race')['income'].median()\n",
    "race['Median loan_amount']=subset.groupby('derived_race')['loan_amount'].median()\n",
    "race['Median interest rate']=subset.groupby('derived_race')['interest_rate'].median()\n",
    "race=race.reindex(['American Indian or Alaska Native','Asian','Black or African American',\n",
    "                 'Native Hawaiian or Other Pacific Islander','White','2 or more minority races',\n",
    "                 'Joint','Free Form Text Only','Race Not Available'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subplots for demographics graphs\n",
    "gs=gridspec.GridSpec(2,2,width_ratios=[1.4,1])\n",
    "fig= plt.figure(figsize=(15,12))\n",
    "\n",
    "# age bar chart\n",
    "ax=plt.subplot(gs[0,0])\n",
    "age_fig=sns.barplot(x=age.index, y='Applications', data=age, color='cyan',\n",
    "                      saturation=.5, edgecolor='.2')\n",
    "age_fig.set(ylabel='Number of Applications', xlabel='Applicant Age Range')\n",
    "fig.suptitle('Figure 1. Demographics of First-time Home Buyers in 2018',\n",
    "          ha='center', weight='bold', fontsize=20, x=.35, y=.92)\n",
    "\n",
    "# gender bar chart\n",
    "ax=plt.subplot(gs[0,1])\n",
    "gender_fig=sns.countplot(x='derived_sex', data=subset, color='khaki', \n",
    "                      edgecolor='black')\n",
    "gender_fig.set_xticklabels(['Male','Female','No info','Joint'])\n",
    "gender_fig.set(xlabel='Applicant Gender', ylabel='')\n",
    "\n",
    "# race bar chart\n",
    "ax=plt.subplot(gs[1,:])\n",
    "race_fig=sns.barplot(y=race.index, x='Applications', data=race, color='sienna',\n",
    "                      saturation=.5, edgecolor='.2')\n",
    "race_fig.set(xlabel='Number of Applications', ylabel='Applicant Race')\n",
    "for i in race_fig.patches:\n",
    "    race_fig.text(i.get_width()+1000, i.get_y()+0.52, str(int(i.get_width())),\n",
    "                  fontweight='bold', fontsize=13)                 \n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "* Even though age group 35-44 has the highest median income and loan amount in the first-time buyers subset, the median interest rates are almost the same for all age groups.\n",
    "\n",
    "* Similarly, in all gender groups, “joint” gender, assuming to be couples, has the highest median income and median loan amount but median interest rate also remains constant across all groups.\n",
    "\n",
    "* On the other hand, American Indian or Alaska Native group has the lowest median income and median loan amount but has the highest median interest rate along with Black or African American. Asian group has the highest median income and median loan amount out of the reported race groups but has the lowest median interest rate.\n",
    "\n",
    "* There is a positive correlation between median loan amount and median income regardless of demographic attributes. \n",
    "* While median income and median loan amount do not seem to affect median interest rate when classify the data by age and sex, there are negative correlations between median interest rate and median income as well as between median interest rate and median loan amount when the dataset is broken down by races. Particularly, higher income and higher loan amount as individual variables result in lower interest rate.  \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression plots for relationships among income, loan amount, interest rate\n",
    "\n",
    "fig, ax = plt.subplots(3,3,figsize=(15,15))\n",
    "fig.suptitle('Figure 2. Median Statistics Measure', x=.5, y=1.02,fontsize=20, fontweight='bold')\n",
    "age_income_interest = sns.regplot(data=age, x='Median income',y='Median interest rate', ax=ax[0,0])\n",
    "age_income_loan = sns.regplot(data=age, x='Median income',y='Median loan_amount', ax=ax[0,1])\n",
    "age_loan_interest = sns.regplot(data=age, x='Median loan_amount',y='Median interest rate', ax=ax[0,2])\n",
    "\n",
    "gender_income_interest = sns.regplot(data=gender, x='Median income',y='Median interest rate', ax=ax[1,0], color='orange')\n",
    "gender_income_loan = sns.regplot(data=gender, x='Median income',y='Median loan_amount', ax=ax[1,1], color='orange')\n",
    "gender_loan_interest = sns.regplot(data=gender, x='Median loan_amount',y='Median interest rate', ax=ax[1,2], color='orange')\n",
    "\n",
    "race_income_interest = sns.regplot(data=race, x='Median income',y='Median interest rate', ax=ax[2,0], color='green')\n",
    "race_income_loan = sns.regplot(data=race, x='Median income',y='Median loan_amount', ax=ax[2,1], color='green')\n",
    "race_loan_interest = sns.regplot(data=race, x='Median loan_amount',y='Median interest rate', ax=ax[2,2], color='green')\n",
    "\n",
    "age_income_interest.legend(labels=['Age'], loc='center left')\n",
    "gender_income_interest.legend(labels=['Gender'], loc='center left')\n",
    "race_income_interest.legend(labels=['Race'], loc='center left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Denial Rate by Races\n",
    "\n",
    "* From column *action_taken* in the dataset, I added a new column called loan_status to categorize “Accepted” and “Denied” applications.\n",
    "    * Accepted applications include value ‘1’- Loan originated, ‘2’- Application approved but not accepted, ‘6’- Purchased loan, and ‘8’- Preapproval request approved but not accepted.\n",
    "    * Denied applications include value ‘3’- Application denied, and ‘7’- Preapproval request denied.\n",
    "    \n",
    "* The denial rate is calculated by dividing the number of denied applications by the total number of applications in the subset. \n",
    "\n",
    "* Denial rate for American Indian or Alaska Native is the highest with over 23%. The denial rates for Native Hawaiian or Other Pacific Islander and 2 or more minority races are also over 20%. Even though there are only under 1,000 mortgage applications for each of these races, which is a very small portion of the subset, these groups have the highest denial rates. In other words, only a small number of applicants who are in minority races qualify for mortgage loans to finance for their new homes.\n",
    "\n",
    "* There are about 50,000 applications that do not report applicants’ race and 6,500 applications with “Joint” race, which could affect the analysis to some extend but it is undeniable that the denial rates of minority races almost double those of others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of applicants classified by race and state\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "all_by_race_table=pd.crosstab(subset.derived_race,df.state_code,margins=True)\n",
    "# print(table1)\n",
    "\n",
    "# Number of denied applicants classified by race and state\n",
    "Denied_data=subset[subset.loan_status == 'Denied']\n",
    "denied_table=pd.crosstab(Denied_data.derived_race,Denied_data.state_code,margins=True)\n",
    "# print(table2)\n",
    "\n",
    "# Percentage of denied applicants classified by race and state\n",
    "denied_by_race_table=denied_table/all_by_race_table\n",
    "denied_by_race_table.fillna(0, inplace=True)\n",
    "denied_by_race_table=denied_by_race_table[['MA','ME','NH','NY','RI','VT','All']]\n",
    "denied_by_race_table=denied_by_race_table.reindex(['American Indian or Alaska Native','Asian','Black or African American',\n",
    "                 'Native Hawaiian or Other Pacific Islander','White','2 or more minority races',\n",
    "                 'Joint','Free Form Text Only','Race Not Available'])\n",
    "# print(table3)\n",
    "\n",
    "# line plot \n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "race_rate=sns.pointplot(x=denied_by_race_table.index, y='All', data=denied_by_race_table, color='purple')\n",
    "race_rate.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: \"%.2f%%\" %(x * 100)))\n",
    "plt.xticks(rotation=60, ha='right')\n",
    "plt.xlabel('Applicant Race')\n",
    "plt.ylabel('Application Denial Rate')\n",
    "plt.title('Figure 3. Denial Rate by Races', weight='bold', fontsize=20, pad=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Denial Reasons For Rejected Applications\n",
    "\n",
    "HMDA requires financial institutions to report reasons for denied applications or denied preapproval requests. In this dataset, there are 8 specific denial reasons recorded. For a total of 30,000 denied applications, the most reported denial reason is Debt-to-Income Ratio, followed by Credit History and Collateral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denial_reason_df=pd.DataFrame(subset[subset['loan_status'] == 'Denied'].denial_reason_1.value_counts())\n",
    "denial_reason_df=denial_reason_df.rename(index={1: 'Debt-to-income ratio', \n",
    "                                                2: 'Employment history',\n",
    "                                                3: 'Credit history',\n",
    "                                                4: 'Collateral',\n",
    "                                                5: 'Insufficient cash (downpayment, closing costs)',\n",
    "                                                6: 'Unverifiable information',\n",
    "                                                7: 'Credit application incomplete',\n",
    "                                                8: 'Mortgage insurance denied',\n",
    "                                                9: 'Other',\n",
    "                                                1111: 'No info'})\n",
    "\n",
    "# bar plot\n",
    "denial_reason_graph=denial_reason_df.plot(kind='barh', figsize=(12,7), edgecolor='black', width=.7)\n",
    "denial_reason_graph.get_legend().remove()\n",
    "denial_reason_graph.invert_yaxis() #sort bars in descending order\n",
    "denial_reason_graph.set(xlabel='Number of Applications', ylabel='Denial Reasons')\n",
    "# add numbers of applications for each bar\n",
    "for i in denial_reason_graph.patches:\n",
    "    denial_reason_graph.text(i.get_width()+50, i.get_y()+0.5, str(round((i.get_width()), 2)), \n",
    "                             fontweight='bold', fontsize=13)\n",
    "plt.title('Figure 4. Denial Reasons', weight='bold', fontsize=20, pad=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debt-to-Income Ratio\n",
    "\n",
    "* Debt-to-income ratio measures the amount of debt the applicants have to their gross income, which helps lenders determine whether the applicants have the ability to afford monthly mortgage payments. \n",
    "\n",
    "* Low debt-to-income ratio is preferable while high ratio indicates that the applicant might have too much liability and is riskier to lenders. However, there is no established “passing” debt-to-income ratio target, so I analyze the denial rate by debt-to-income ratios.\n",
    "\n",
    "* The denial rate remains under 10% for debt-to-income ratio from 20% to 45%.\n",
    "\n",
    "* Starting with ratio of 46% onwards, the denial rates seem to increase closer to 10% and jumps to 23% with 50%-60% ratio mark. \n",
    "\n",
    "* Over 80% of the applications with more than 60% debt-to-income ratio are rejected. \n",
    "\n",
    "* Surprisingly, even with a debt-to-income ratio of under 20%, the denial rate is about 11% which is noticeably higher than other ratio levels. A potential explanation is that these applicants have not had established credit history due to the lack of frequent liability payments; therefore, they might be rejected because of credit history reason rather than debt-to-income ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of applicants classified by debt/income and state\n",
    "all_by_debt_ratio_table=pd.crosstab(subset.state_code,subset.debt_to_income_ratio,margins=True)\n",
    "\n",
    "# Number of denied applicants classified by debt/income and state\n",
    "denied_by_debt_ratio_table=pd.crosstab(Denied_data.state_code,Denied_data.debt_to_income_ratio,margins=True)\n",
    "\n",
    "# Percentage of denied applicants classified by debt/income and state\n",
    "denied_pct_table=denied_by_debt_ratio_table/all_by_debt_ratio_table\n",
    "\n",
    "# selecting only 'All' row\n",
    "denied_pct_table_sub=pd.DataFrame(denied_pct_table.loc['All'])\n",
    "denied_pct_table_sub.drop('All')\n",
    "denied_pct_table_sub=denied_pct_table_sub.reindex(['<20%','20%-<30%','30%-<36%','36','37','38','39','40',\n",
    "                 '41','42','43','44','45','46','47','48','49','50%-60%',\n",
    "                 '>60%','Exempt'])\n",
    "denied_pct_table_sub=denied_pct_table_sub.rename(index={'36':'36%','37':'37%','38':'38%','39':'39%','40':'40%',\n",
    "                 '41':'41%','42':'42%','43':'43%','44':'44%','45':'45%','46':'46%','47':'47%',\n",
    "                 '48':'48%','49':'49%'})\n",
    "\n",
    "# line plot\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "ratio_rate=sns.pointplot(x=denied_pct_table_sub.index, y='All', data=denied_pct_table_sub, color='green')\n",
    "ratio_rate.yaxis.set_major_formatter(ticker.FuncFormatter(lambda x, pos: '%4d%%'%(x * 100)))\n",
    "plt.xticks(rotation=30, ha='right')\n",
    "plt.xlabel('Debt-to-Income Ratio')\n",
    "plt.ylabel('Denial Rate')\n",
    "plt.title('Figure 5. Denial Rate by Debt-to-Income Ratio', weight='bold', fontsize=20, pad=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loan Types\n",
    "\n",
    "* Approximately 83% the total mortgage loan applications are for Conventional loan while only 12% of applications are for FHA loan. Conventional loans are believed to provide more flexibility to borrowers in term of down payment options, loan term lengths, etc. Thus, conventional loans are more common to home buyers. \n",
    "\n",
    "* Only about one-third of the Conventional loan applications are from first-time home buyers. It is possible that first-time home buyers are less likely to qualify for Conventional loan. Because Conventional loan is not guaranteed by the government, the lender is at risk if the borrower cannot make mortgage payments so Conventional loan typically has higher requirements.\n",
    "\n",
    "* Nearly 50% of the FHA loan applications are from first-time buyers. FHA loan is one of the government-backed loans, which requires lower income and lower credit score, making it easier for first-time home buyers to be qualified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of applications by loan types for both first-time buyers subset and all buyers\n",
    "\n",
    "all_loan = df.loan_type.value_counts()/len(df.loan_type)\n",
    "first_time_loan = subset.loan_type.value_counts()/df.loan_type.value_counts()\n",
    "\n",
    "# bar chart\n",
    "fig, ax = plt.subplots(figsize=(17,4)) #change graph size\n",
    "\n",
    "all_buyers=sns.countplot(y='loan_type', data=df, color='darksalmon', edgecolor='black')\n",
    "ft_buyers=sns.countplot(y='loan_type', data=subset, color='steelblue', edgecolor='black')\n",
    "\n",
    "plt.legend(labels=['Other home buyers', 'First-time home buyers'], loc='lower right')\n",
    "all_buyers.set_xticks([0,100000,200000,300000,400000,500000,600000,700000,800000,900000])\n",
    "all_buyers.set_yticklabels(['Conventional', 'FHA','VA','USDA'])\n",
    "plt.xlabel('Number of Applications')\n",
    "plt.ylabel('Loan Types')\n",
    "plt.title('Figure 6. Applications Distribution by Loan Types', weight='bold', fontsize=20, pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Statistical Analysis\n",
    "\n",
    "#### Bootstrap confidence intervals\n",
    "\n",
    "I want to obtain more insights on *income*, *loan_amount*, and *property_value* columns but because the subset of first-time home buyers is only an estimation, I'm not confident that the data accurately represents the actual population of first-time home buyers. There are many outliers that could drastically affect the analysis. However, there is not enough evidence to surely determine whether these outliers are rare exceptions, or that they actually don’t belong in this subset. Therefore, I consider this current data subset as a sample of first-time buyers’ population. I compute bootstrap confidence intervals of *income*, *loan_amount*, and *property_value* columns to get a more assured results.\n",
    "\n",
    "* Generate bootstrap replicates and calculate the 90% confidence intervals for *income*, *loan_amount*, and *property_value* columns. \n",
    "\n",
    "* A size of 10,000 is used for the bootstrap replicates because this is a large dataset and it would take a long time to complete the analysis with larger size.\n",
    "\n",
    "* Confidence intervals give us the estimation of discrepancy from the sample mean to population mean. With a 90% confidence interval, we can be 90% confident that the interval will contain the actual population mean.\n",
    "\n",
    "    * __Income:__ The 90% confidence interval for income is between 125.91545 and 126.82015, meaning the average income of the first-time home buyers segment is around $125,915 to $126,820.\n",
    "    * __Loan Amount:__ The 90% confidence interval for loan amount is between 323.98419 and 325.48487. This range indicates that first-time home buyers apply for mortgage loan of $324,984 to $325,485 on average.\n",
    "    * __Property Value:__ The 90% confidence interval for property value is between 423.34171 and 426.3167, indicating that first-time home buyers apply for mortgage loan to finance a home with an average price of $423,342 to $426,317.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make values in property_value column in thousands of dollars\n",
    "# to be consistent with income and loan amount\n",
    "subset['property_value']= subset.property_value/1000\n",
    "\n",
    "# Draw bootstrap replicates\n",
    "def draw_bs_reps(data, func,size=1):\n",
    "    n = len(data)\n",
    "    reps = np.empty(size)\n",
    "    for i in range(size):\n",
    "        bs_sample = np.random.choice(data, n)\n",
    "        reps[i] = func(bs_sample)     \n",
    "    return reps\n",
    "\n",
    "# bootstrap confidence interval of income\n",
    "print('income')\n",
    "bs_reps_income =draw_bs_reps(subset['income'], np.mean, size=10000)\n",
    "sem = np.std(subset.income) / np.sqrt(len(subset.income))\n",
    "print(sem)\n",
    "\n",
    "conf_int = np.percentile(bs_reps_income,[5,90])\n",
    "print('90% confidence interval =', conf_int)\n",
    "print('\\n')\n",
    "\n",
    "# bootstrap confidence interval of loan amount\n",
    "print('loan_amount')\n",
    "bs_reps_loan_amount =draw_bs_reps(subset['loan_amount'], np.mean, size=10000)\n",
    "sem = np.std(subset.loan_amount) / np.sqrt(len(subset.loan_amount))\n",
    "print(sem)\n",
    "\n",
    "conf_int = np.percentile(bs_reps_loan_amount,[5,90])\n",
    "print('90% confidence interval =', conf_int)\n",
    "print('\\n')\n",
    "\n",
    "# exclude nan values for the confidence interval test\n",
    "subset1=subset[(subset.property_value>0)]\n",
    "\n",
    "# bootstrap confidence interval of property_value \n",
    "print('property_value')\n",
    "bs_reps_property_value =draw_bs_reps(subset1['property_value'], np.mean, size=10000)\n",
    "sem = np.std(subset1.property_value) / np.sqrt(len(subset1.property_value))\n",
    "print(sem)\n",
    "\n",
    "conf_int = np.percentile(bs_reps_property_value,[5,90])\n",
    "print('90% confidence interval =', conf_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram plots\n",
    "fig=plt.figure(figsize=(21,7))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "inc_ci= sns.histplot(bs_reps_income)\n",
    "inc_ci.set(xlabel='Mean Income (in 1000s)', ylabel='Probability Density Function')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "loan_ci= sns.histplot(bs_reps_loan_amount)\n",
    "loan_ci.set(xlabel='Mean Loan Amount (in 1000s)', ylabel='Probability Density Function')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "value_ci= sns.histplot(bs_reps_property_value)\n",
    "value_ci.set(xlabel='Mean Property Value (in 1000s)', ylabel='Probability Density Function')\n",
    "\n",
    "fig.suptitle('Figure 7. Bootstrap Confidence Intervals', fontweight='bold', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Machine Learning Technique\n",
    "\n",
    "#### Logistic Regresion Model\n",
    "\n",
    "Since I could not identify clear direct relationships due to data variation in this dataset, logistics regression model is a good method to quantify the correlations of different components. Based on the exploratory data analysis and statistical summary, I select 7 candidate variables including *applicant_age*, *debt_to_income_ratio*, *income*, *loan_amount*, *derived_sex*, *loan_type*, and *derived_race* to build the logistic regression model.The response of this model is the odds of application approved/ odds of application denied.\n",
    "* The ‘Approved’ value in loan_status column is replaced with number 1 and ‘Denied’ value with number 0.\n",
    "* In order to reduce the number of dummy variables, I convert string values of *applicant_age* and *debt_to_income_ratio* columns into numeric value.\n",
    "* Rows with *derived_race* = ‘race not available’, *derived_sex* = ‘sex not available’, and *applicant_age* = ‘Exempt’ are removed.\n",
    "* The data subset used for the regression model contains 263,043 observations, around one-third of the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change age to numeric data\n",
    "subset['applicant_age'] = subset['applicant_age'].replace(['<25', '25-34', '35-44', '45-54', '55-64', '65-74', '>74'], [22,30,40,50,60,70,79])\n",
    "\n",
    "# Change string of debt_to_income_ratio to numeric data\n",
    "subset['debt_to_income_ratio'] = subset['debt_to_income_ratio'].replace(['<20%', '20%-<30%', '30%-<36%', '50%-60%', '>60%'], [10,25,33,55,70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe that include only variables for regression model\n",
    "regressiondata = subset[['loan_status','income', 'loan_amount','applicant_age','debt_to_income_ratio']]\n",
    "\n",
    "# Remove not avaible values and nan values\n",
    "regressiondata = regressiondata.replace('Exempt',None)\n",
    "regressiondata = regressiondata.drop(regressiondata[regressiondata['applicant_age'] == '8888'].index)\n",
    "subset = subset.replace(['Race Not Available', 'Sex Not Available'],None)\n",
    "regressiondata.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "\n",
    "regressiondata[['debt_to_income_ratio']]=regressiondata[['debt_to_income_ratio']].astype(int)\n",
    "\n",
    "# Create dummy variables\n",
    "dummyrace = pd.get_dummies(subset['derived_race'], prefix='race') \n",
    "dummytype = pd.get_dummies(subset['loan_type'],prefix='type')\n",
    "dummygender = pd.get_dummies(subset['derived_sex'])\n",
    "\n",
    "# Create regression data\n",
    "regressiondata=regressiondata.join(dummyrace.loc[:,'race_Asian':]).join(dummytype.loc[:,'type_2':]).join(dummygender.loc[:,'Joint':])\n",
    "\n",
    "#Insert Intercept\n",
    "regressiondata['intercept'] = 1.0\n",
    "\n",
    "# X value\n",
    "train_cols = regressiondata.columns[1:]\n",
    "\n",
    "# Y value\n",
    "regressiondata.loc[regressiondata['loan_status'] == 'Approved','loan_status'] = 1\n",
    "regressiondata.loc[regressiondata['loan_status'] == 'Denied','loan_status'] = 0\n",
    "\n",
    "# Create regression model\n",
    "logit = sm.Logit(regressiondata['loan_status'].astype(float), regressiondata[train_cols].astype(float))\n",
    "\n",
    "# fit the model\n",
    "result = logit.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model\n",
    "X_train, X_test, y_train, y_test = train_test_split(regressiondata[train_cols],regressiondata['loan_status'].astype('int'), test_size=0.25, random_state=0)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Creat confusion matrix\n",
    "confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.heatmap(confusion_matrix, annot=True)\n",
    "\n",
    "print('Accuracy: ',metrics.accuracy_score(y_test, y_pred))\n",
    "plt.title('Figure 9. Confusion Matrix Heatmap', weight='bold', fontsize=20, pad=20)\n",
    "plt.show()\n"
   ]
  },
  {
   "source": [
    "Most factors are statistically significant at the significance level of 0.05 except race_Free. The coefficient of variables is interpreted below.\n",
    "* income – For a one-unit increase in **income**, we expect the odds of application approval decrease by 0.6% (exp(-0.0006)=1.0006%)), holding all other independent variables constant.\n",
    "* loan_amount – For a one-unit increase in **loan_amount**, we expect the odds of application approval increase by 0.8%, holding all other independent variables constant.\n",
    "* applicant_age – For a one-unit increase in **applicant_age**, we expect the odds of application approval increase by 13.1%, holding all other independent variables constant.\n",
    "* debt_to_income_ratio – For a one-unit increase in **debt_to_income_ratio**, we expect the odds of application approval decrease by 7.28%, holding all other independent variables constant.\n",
    "* race_Asian – Asian have 119.3% higher odds than American Indian or Alaska native to get application approval, holding all other independent variables constant.\n",
    "* race_Black or African American – Black or African American have 63.7% higher odds than American Indian or Alaska Native to get application approval, holding all other independent variables constant.\n",
    "* race_Joint – Joint races have 125.9% higher odds than American Indian or Alaska Native to get application approval, holding all other independent variables constant.\n",
    "* race_White – White race have 161.5% higher odds than American Indian or Alaska Native to get application approval, holding all other independent variables constant.\n",
    "* Type_2 – **FHA loan** application has 32.3% higher odds than conventional loan to be approved, holding all other independent variables constant.\n",
    "* Type_3 – **VA loan** application has 30.6% higher odds than conventional loan to be approved, holding all other independent variables constant.\n",
    "* Type_4 – **RHS or FSA loan** application has 103.4% lower odds than conventional loan to be approved, holding all other independent variables constant.\n",
    "* Joint – **Joint** genders has 15.8% higher odds than female to get the application approval, holding all other independent variables constant.\n",
    "* Male – **Male** has 13.7% lower odds than female to get the application approval, holding all other independent variables constant.\n",
    "\n",
    "The R square of this regression model is 9.32%, indicating that 9.32% of loan status change can be explained by gender, age, race, loan type, loan amount, debt-to-income ratio and income. This regression analysis implies that the odds of application approved/ denied have positive correlations with loan amount, and have negative correlations with income, age, debt to income ratio. \n",
    "\n",
    "However, based on the exploratory data analysis earlier, people with higher income are more likely to get application approval. I attribute this conflict to the autocorrelation between income and debt-to-income ratio. Because the coefficient of income is very small, this conflict will not affect our final analysis conclusion."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 5 - Recommendations\n",
    "\n",
    "#### Lower interest rate for young buyers\n",
    "\n",
    "From the statistical summary, we can see that interest rates stay the same for all age groups despite the difference in number of applications across groups. With a high amount of applications from 25-34 and 35-44 age groups, legislators should focus on helping applicants in these age range. The younger buyers are more likely to have existing liabilities such as student loan, auto loan to pay off. Thus, legislators should consider lowering interest rates for younger buyers in order to give them more possibility to afford a home.\n",
    "\n",
    "#### Improve approval rate for applicants in minority groups\n",
    "\n",
    "The analyses on first-time home buyers’ demographic attributes and denial rate by races demonstrate that applicants from minorities have substantially low chance to get their loan mortgage applications approved. As a result, legislators should consider develop regulations to support applicants in minority groups. Nonetheless, nearly 20% of the applications in this dataset do not provide racial information. Our consulting group should helps legislators conduct more research and collect more evidence to verify my initial analysis as well as identify any other complex reasons for low approval rates.\n",
    "\n",
    "#### Educate buyers to repay their debts as much as possible before applying for home mortgage\n",
    "\n",
    "There is a strong negative correlation between debt-to-income ratio and application approval rate, indicating that people should evaluate their debt and income before their home mortgage application. Legislators should help educate home buyers on optimizing their debt-to-asset structure, including repaying their debt as much as possible, so that the risk of application being denied can be lower. \n",
    "\n",
    "#### Investigate the reasons for extremely low approval rate for RHS/FSA loan applications \n",
    "\n",
    "Based on regression analysis, RHS/FSA loan applications are much more likely to be denied than other loan types, and VA loan applications are much more likely to be approved than other types. Government should look into the cause for such big differences in different types of loan, and then adjust the threshold of the loan requirements or provide more guidance to applicants about how to choose the most suitable loan mortgage.\n",
    "\n",
    "#### Promote FHA loans\n",
    "\n",
    "Even though conventional loan has more applications overall, only one-third of the applications are from first-time home buyers while FHA loan applications have bigger fraction of first-time home buyers. Legislators should consider promoting FHA loans more extensively to first-time home buyers and potentially adjust loan standards to make it more accessible. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}